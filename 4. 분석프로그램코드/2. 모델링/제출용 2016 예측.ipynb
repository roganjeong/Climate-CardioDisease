{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1618d3-6183-4ff3-bc52-c01ad829fc80",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cd94e-2fc3-4834-b1fb-d9da8a6478d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed119834-4ef9-41e5-8a4b-46f8aa4fb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/jupyter/climate/data/TRAIN_tree_with_파생변수0804.csv')\n",
    "train.drop(['Unnamed: 0', 'yyyymmdd'], axis=1, inplace=True)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "train_Gangwon_1 = train[(train['add'] == '강원') & (train['sex'] == 1)]\n",
    "train_Gangwon_2 = train[(train['add'] == '강원') & (train['sex'] == 2)]\n",
    "\n",
    "train_Gyeonggi_1 = train[(train['add'] == '경기') & (train['sex'] == 1)]\n",
    "train_Gyeonggi_2 = train[(train['add'] == '경기') & (train['sex'] == 2)]\n",
    "\n",
    "train_Gyeongnam_1 = train[(train['add'] == '경남') & (train['sex'] == 1)]\n",
    "train_Gyeongnam_2 = train[(train['add'] == '경남') & (train['sex'] == 2)]\n",
    "\n",
    "train_Gyeongbuk_1 = train[(train['add'] == '경북') & (train['sex'] == 1)]\n",
    "train_Gyeongbuk_2 = train[(train['add'] == '경북') & (train['sex'] == 2)]\n",
    "\n",
    "train_Gwangju_1 = train[(train['add'] == '광주') & (train['sex'] == 1)]\n",
    "train_Gwangju_2 = train[(train['add'] == '광주') & (train['sex'] == 2)]\n",
    "\n",
    "train_Daegu_1 = train[(train['add'] == '대구') & (train['sex'] == 1)]\n",
    "train_Daegu_2 = train[(train['add'] == '대구') & (train['sex'] == 2)]\n",
    "\n",
    "train_Daejeon_1 = train[(train['add'] == '대전') & (train['sex'] == 1)]\n",
    "train_Daejeon_2 = train[(train['add'] == '대전') & (train['sex'] == 2)]\n",
    "\n",
    "train_Busan_1 = train[(train['add'] == '부산') & (train['sex'] == 1)]\n",
    "train_Busan_2 = train[(train['add'] == '부산') & (train['sex'] == 2)]\n",
    "\n",
    "train_Seoul_1 = train[(train['add'] == '서울') & (train['sex'] == 1)]\n",
    "train_Seoul_2 = train[(train['add'] == '서울') & (train['sex'] == 2)]\n",
    "\n",
    "train_Sejong_1 = train[(train['add'] == '세종') & (train['sex'] == 1)]\n",
    "train_Sejong_2 = train[(train['add'] == '세종') & (train['sex'] == 2)]\n",
    "\n",
    "train_Ulsan_1 = train[(train['add'] == '울산') & (train['sex'] == 1)]\n",
    "train_Ulsan_2 = train[(train['add'] == '울산') & (train['sex'] == 2)]\n",
    "\n",
    "train_Incheon_1 = train[(train['add'] == '인천') & (train['sex'] == 1)]\n",
    "train_Incheon_2 = train[(train['add'] == '인천') & (train['sex'] == 2)]\n",
    "\n",
    "train_Jeonnam_1 = train[(train['add'] == '전남') & (train['sex'] == 1)]\n",
    "train_Jeonnam_2 = train[(train['add'] == '전남') & (train['sex'] == 2)]\n",
    "\n",
    "train_Jeonbuk_1 = train[(train['add'] == '전북') & (train['sex'] == 1)]\n",
    "train_Jeonbuk_2 = train[(train['add'] == '전북') & (train['sex'] == 2)]\n",
    "\n",
    "train_Jeju_1 = train[(train['add'] == '제주') & (train['sex'] == 1)]\n",
    "train_Jeju_2 = train[(train['add'] == '제주') & (train['sex'] == 2)]\n",
    "\n",
    "train_Chungnam_1 = train[(train['add'] == '충남') & (train['sex'] == 1)]\n",
    "train_Chungnam_2 = train[(train['add'] == '충남') & (train['sex'] == 2)]\n",
    "\n",
    "train_Chungbuk_1 = train[(train['add'] == '충북') & (train['sex'] == 1)]\n",
    "train_Chungbuk_2 = train[(train['add'] == '충북') & (train['sex'] == 2)]\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "train_Gangwon_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Gangwon_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Gyeonggi_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Gyeonggi_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Gyeongnam_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Gyeongnam_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Gyeongbuk_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Gyeongbuk_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Gwangju_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Gwangju_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Daegu_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Daegu_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Daejeon_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Daejeon_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Busan_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Busan_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Seoul_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Seoul_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Sejong_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Sejong_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Ulsan_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Ulsan_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Incheon_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Incheon_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Jeonnam_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Jeonnam_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Jeonbuk_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Jeonbuk_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Jeju_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Jeju_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Chungnam_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Chungnam_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "train_Chungbuk_1.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "train_Chungbuk_2.drop(['add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "y_train_Gangwon_1 = train_Gangwon_1['frequency']\n",
    "y_train_Gangwon_2 = train_Gangwon_2['frequency']\n",
    "train_Gangwon_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Gangwon_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Gyeonggi_1 = train_Gyeonggi_1['frequency']\n",
    "y_train_Gyeonggi_2 = train_Gyeonggi_2['frequency']\n",
    "train_Gyeonggi_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Gyeonggi_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Gyeongnam_1 = train_Gyeongnam_1['frequency']\n",
    "y_train_Gyeongnam_2 = train_Gyeongnam_2['frequency']\n",
    "train_Gyeongnam_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Gyeongnam_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Gyeongbuk_1 = train_Gyeongbuk_1['frequency']\n",
    "y_train_Gyeongbuk_2 = train_Gyeongbuk_2['frequency']\n",
    "train_Gyeongbuk_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Gyeongbuk_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Gwangju_1 = train_Gwangju_1['frequency']\n",
    "y_train_Gwangju_2 = train_Gwangju_2['frequency']\n",
    "train_Gwangju_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Gwangju_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Daegu_1 = train_Daegu_1['frequency']\n",
    "y_train_Daegu_2 = train_Daegu_2['frequency']\n",
    "train_Daegu_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Daegu_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Daejeon_1 = train_Daejeon_1['frequency']\n",
    "y_train_Daejeon_2 = train_Daejeon_2['frequency']\n",
    "train_Daejeon_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Daejeon_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Busan_1 = train_Busan_1['frequency']\n",
    "y_train_Busan_2 = train_Busan_2['frequency']\n",
    "train_Busan_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Busan_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Seoul_1 = train_Seoul_1['frequency']\n",
    "y_train_Seoul_2 = train_Seoul_2['frequency']\n",
    "train_Seoul_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Seoul_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Sejong_1 = train_Sejong_1['frequency']\n",
    "y_train_Sejong_2 = train_Sejong_2['frequency']\n",
    "train_Sejong_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Sejong_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Ulsan_1 = train_Ulsan_1['frequency']\n",
    "y_train_Ulsan_2 = train_Ulsan_2['frequency']\n",
    "train_Ulsan_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Ulsan_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Incheon_1 = train_Incheon_1['frequency']\n",
    "y_train_Incheon_2 = train_Incheon_2['frequency']\n",
    "train_Incheon_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Incheon_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Jeonnam_1 = train_Jeonnam_1['frequency']\n",
    "y_train_Jeonnam_2 = train_Jeonnam_2['frequency']\n",
    "train_Jeonnam_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Jeonnam_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Jeonbuk_1 = train_Jeonbuk_1['frequency']\n",
    "y_train_Jeonbuk_2 = train_Jeonbuk_2['frequency']\n",
    "train_Jeonbuk_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Jeonbuk_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Jeju_1 = train_Jeju_1['frequency']\n",
    "y_train_Jeju_2 = train_Jeju_2['frequency']\n",
    "train_Jeju_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Jeju_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Chungnam_1 = train_Chungnam_1['frequency']\n",
    "y_train_Chungnam_2 = train_Chungnam_2['frequency']\n",
    "train_Chungnam_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Chungnam_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n",
    "y_train_Chungbuk_1 = train_Chungbuk_1['frequency']\n",
    "y_train_Chungbuk_2 = train_Chungbuk_2['frequency']\n",
    "train_Chungbuk_1.drop(['frequency'], axis=1, inplace=True)\n",
    "train_Chungbuk_2.drop(['frequency'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7e2c5-4280-4d35-adcf-42f400052c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/jupyter/climate/data/TEST_with_파생변수0804.csv', header = 0 )\n",
    "\n",
    "test_Gangwon_1 = test[(test['add'] == '강원') & (test['sex'] == 1)]\n",
    "test_Gangwon_2 = test[(test['add'] == '강원') & (test['sex'] == 2)]\n",
    "\n",
    "test_Gyeonggi_1 = test[(test['add'] == '경기') & (test['sex'] == 1)]\n",
    "test_Gyeonggi_2 = test[(test['add'] == '경기') & (test['sex'] == 2)]\n",
    "\n",
    "test_Gyeongnam_1 = test[(test['add'] == '경남') & (test['sex'] == 1)]\n",
    "test_Gyeongnam_2 = test[(test['add'] == '경남') & (test['sex'] == 2)]\n",
    "\n",
    "test_Gyeongbuk_1 = test[(test['add'] == '경북') & (test['sex'] == 1)]\n",
    "test_Gyeongbuk_2 = test[(test['add'] == '경북') & (test['sex'] == 2)]\n",
    "\n",
    "test_Gwangju_1 = test[(test['add'] == '광주') & (test['sex'] == 1)]\n",
    "test_Gwangju_2 = test[(test['add'] == '광주') & (test['sex'] == 2)]\n",
    "\n",
    "test_Daegu_1 = test[(test['add'] == '대구') & (test['sex'] == 1)]\n",
    "test_Daegu_2 = test[(test['add'] == '대구') & (test['sex'] == 2)]\n",
    "\n",
    "test_Daejeon_1 = test[(test['add'] == '대전') & (test['sex'] == 1)]\n",
    "test_Daejeon_2 = test[(test['add'] == '대전') & (test['sex'] == 2)]\n",
    "\n",
    "test_Busan_1 = test[(test['add'] == '부산') & (test['sex'] == 1)]\n",
    "test_Busan_2 = test[(test['add'] == '부산') & (test['sex'] == 2)]\n",
    "\n",
    "test_Seoul_1 = test[(test['add'] == '서울') & (test['sex'] == 1)]\n",
    "test_Seoul_2 = test[(test['add'] == '서울') & (test['sex'] == 2)]\n",
    "\n",
    "test_Sejong_1 = test[(test['add'] == '세종') & (test['sex'] == 1)]\n",
    "test_Sejong_2 = test[(test['add'] == '세종') & (test['sex'] == 2)]\n",
    "\n",
    "test_Ulsan_1 = test[(test['add'] == '울산') & (test['sex'] == 1)]\n",
    "test_Ulsan_2 = test[(test['add'] == '울산') & (test['sex'] == 2)]\n",
    "\n",
    "test_Incheon_1 = test[(test['add'] == '인천') & (test['sex'] == 1)]\n",
    "test_Incheon_2 = test[(test['add'] == '인천') & (test['sex'] == 2)]\n",
    "\n",
    "test_Jeonnam_1 = test[(test['add'] == '전남') & (test['sex'] == 1)]\n",
    "test_Jeonnam_2 = test[(test['add'] == '전남') & (test['sex'] == 2)]\n",
    "\n",
    "test_Jeonbuk_1 = test[(test['add'] == '전북') & (test['sex'] == 1)]\n",
    "test_Jeonbuk_2 = test[(test['add'] == '전북') & (test['sex'] == 2)]\n",
    "\n",
    "test_Jeju_1 = test[(test['add'] == '제주') & (test['sex'] == 1)]\n",
    "test_Jeju_2 = test[(test['add'] == '제주') & (test['sex'] == 2)]\n",
    "\n",
    "test_Chungnam_1 = test[(test['add'] == '충남') & (test['sex'] == 1)]\n",
    "test_Chungnam_2 = test[(test['add'] == '충남') & (test['sex'] == 2)]\n",
    "\n",
    "test_Chungbuk_1 = test[(test['add'] == '충북') & (test['sex'] == 1)]\n",
    "test_Chungbuk_2 = test[(test['add'] == '충북') & (test['sex'] == 2)]\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "test_Gangwon_1.drop(['Unnamed: 0','Unnamed..0','yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Gangwon_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Gyeonggi_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Gyeonggi_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Gyeongnam_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Gyeongnam_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Gyeongbuk_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Gyeongbuk_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Gwangju_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Gwangju_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Daegu_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Daegu_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Daejeon_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Daejeon_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Busan_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Busan_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Seoul_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Seoul_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Sejong_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Sejong_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Ulsan_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Ulsan_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Incheon_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Incheon_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Jeonnam_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Jeonnam_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Jeonbuk_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Jeonbuk_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Jeju_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Jeju_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Chungnam_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Chungnam_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "test_Chungbuk_1.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)\n",
    "test_Chungbuk_2.drop(['Unnamed: 0','Unnamed..0', 'yyyymmdd', 'frequency', 'add', 'sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af00162-403d-4749-9de8-2355c32a8624",
   "metadata": {},
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b480913-339f-44d6-b276-41309e1fe68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, LGBMRanker, LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import psutil\n",
    "import time \n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da9d3d-9d15-4246-a7cc-6913c9b118a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gangwon_1, y_train_Gangwon_1):\n",
    "    x_train, x_val = train_Gangwon_1.iloc[train_index], train_Gangwon_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gangwon_1.iloc[train_index], y_train_Gangwon_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 10,\n",
    "                                  max_leaf_nodes = 70,\n",
    "                                  n_estimators = 242, \n",
    "                                  ccp_alpha = 0.04364)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gangwon_1 = model.predict(test_Gangwon_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da858dbd-71aa-4416-8e36-b27b4cbcdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gangwon_2, y_train_Gangwon_2):\n",
    "    x_train, x_val = train_Gangwon_2.iloc[train_index], train_Gangwon_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gangwon_2.iloc[train_index], y_train_Gangwon_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 484,\n",
    "                                  n_estimators = 141, \n",
    "                                  ccp_alpha = 0.02401)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gangwon_2 = model.predict(test_Gangwon_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73104b-9a02-45db-bbfa-45b50dc29a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeonggi_1, y_train_Gyeonggi_1):\n",
    "    x_train, x_val = train_Gyeonggi_1.iloc[train_index], train_Gyeonggi_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeonggi_1.iloc[train_index], y_train_Gyeonggi_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 569,\n",
    "                                  n_estimators = 333, \n",
    "                                  ccp_alpha = 0.0103)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeonggi_1 = model.predict(test_Gyeonggi_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006b298-079f-4656-81ed-6c0dd6aaf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeonggi_2, y_train_Gyeonggi_2):\n",
    "    x_train, x_val = train_Gyeonggi_2.iloc[train_index], train_Gyeonggi_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeonggi_2.iloc[train_index], y_train_Gyeonggi_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 619,\n",
    "                                  n_estimators = 447, \n",
    "                                  ccp_alpha = 0.068123)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeonggi_2 = model.predict(test_Gyeonggi_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9897e8-7520-4713-9d04-e624e1e51e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeongnam_1, y_train_Gyeongnam_1):\n",
    "    x_train, x_val = train_Gyeongnam_1.iloc[train_index], train_Gyeongnam_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeongnam_1.iloc[train_index], y_train_Gyeongnam_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 6,\n",
    "                                  max_leaf_nodes = 243,\n",
    "                                  n_estimators = 405, \n",
    "                                  ccp_alpha = 0.017205)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeongnam_1 = model.predict(test_Gyeongnam_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ddfbd-face-4d5e-802b-d332005b45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeongnam_2, y_train_Gyeongnam_2):\n",
    "    x_train, x_val = train_Gyeongnam_2.iloc[train_index], train_Gyeongnam_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeongnam_2.iloc[train_index], y_train_Gyeongnam_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 2,\n",
    "                                  max_leaf_nodes = 529,\n",
    "                                  n_estimators = 448, \n",
    "                                  ccp_alpha = 0.028958)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeongnam_2 = model.predict(test_Gyeongnam_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddd04f-03a9-42bc-a40e-4405c9debe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeongbuk_1, y_train_Gyeongbuk_1):\n",
    "    x_train, x_val = train_Gyeongbuk_1.iloc[train_index], train_Gyeongbuk_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeongbuk_1.iloc[train_index], y_train_Gyeongbuk_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 20,\n",
    "                                  max_leaf_nodes = 301,\n",
    "                                  n_estimators = 495, \n",
    "                                  ccp_alpha = 0.037449)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeongbuk_1 = model.predict(test_Gyeongbuk_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca0c3e-5760-4fce-b1be-a8bae88744c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gyeongbuk_2, y_train_Gyeongbuk_2):\n",
    "    x_train, x_val = train_Gyeongbuk_2.iloc[train_index], train_Gyeongbuk_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gyeongbuk_2.iloc[train_index], y_train_Gyeongbuk_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 17,\n",
    "                                  max_leaf_nodes = 870,\n",
    "                                  n_estimators = 470, \n",
    "                                  ccp_alpha = 0.04024)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gyeongbuk_2 = model.predict(test_Gyeongbuk_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfff37e-4c6a-4896-bf23-a17b9339b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gwangju_1, y_train_Gwangju_1):\n",
    "    x_train, x_val = train_Gwangju_1.iloc[train_index], train_Gwangju_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gwangju_1.iloc[train_index], y_train_Gwangju_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 16,\n",
    "                                  max_leaf_nodes = 380,\n",
    "                                  n_estimators = 109, \n",
    "                                  ccp_alpha = 0.014425)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gwangju_1 = model.predict(test_Gwangju_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2435e8-3116-45c0-91cb-73dc38404b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Gwangju_2, y_train_Gwangju_2):\n",
    "    x_train, x_val = train_Gwangju_2.iloc[train_index], train_Gwangju_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Gwangju_2.iloc[train_index], y_train_Gwangju_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 669,\n",
    "                                  n_estimators = 230, \n",
    "                                  ccp_alpha = 0.010673)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Gwangju_2 = model.predict(test_Gwangju_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d8b26-95ce-4321-9afc-04a405419b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Daegu_1, y_train_Daegu_1):\n",
    "    x_train, x_val = train_Daegu_1.iloc[train_index], train_Daegu_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Daegu_1.iloc[train_index], y_train_Daegu_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 10,\n",
    "                                  max_leaf_nodes = 461,\n",
    "                                  n_estimators = 500, \n",
    "                                  ccp_alpha = 0.022992)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Daegu_1 = model.predict(test_Daegu_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818851c9-ad84-41ed-bbc9-c169e9b9cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Daegu_2, y_train_Daegu_2):\n",
    "    x_train, x_val = train_Daegu_2.iloc[train_index], train_Daegu_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Daegu_2.iloc[train_index], y_train_Daegu_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 542,\n",
    "                                  n_estimators = 423, \n",
    "                                  ccp_alpha = 0.011445)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Daegu_2 = model.predict(test_Daegu_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61633a-8b84-4c19-94d3-c6e497c0a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Daejeon_1, y_train_Daejeon_1):\n",
    "    x_train, x_val = train_Daejeon_1.iloc[train_index], train_Daejeon_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Daejeon_1.iloc[train_index], y_train_Daejeon_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 506,\n",
    "                                  n_estimators = 310, \n",
    "                                  ccp_alpha = 0.016068)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Daejeon_1 = model.predict(test_Daejeon_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644cb5e-32f7-4850-b065-5ec6d992da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Daejeon_2, y_train_Daejeon_2):\n",
    "    x_train, x_val = train_Daejeon_2.iloc[train_index], train_Daejeon_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Daejeon_2.iloc[train_index], y_train_Daejeon_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 17,\n",
    "                                  max_leaf_nodes = 63,\n",
    "                                  n_estimators = 465, \n",
    "                                  ccp_alpha = 0.044733)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Daejeon_2 = model.predict(test_Daejeon_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d831583-cfed-4148-8a21-f8fda13b4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Busan_1, y_train_Busan_1):\n",
    "    x_train, x_val = train_Busan_1.iloc[train_index], train_Busan_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Busan_1.iloc[train_index], y_train_Busan_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 7,\n",
    "                                  max_leaf_nodes = 994,\n",
    "                                  n_estimators = 393, \n",
    "                                  ccp_alpha = 0.027409)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Busan_1 = model.predict(test_Busan_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c791a-c206-4f1b-a2ed-fc2e93e07360",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Busan_2, y_train_Busan_2):\n",
    "    x_train, x_val = train_Busan_2.iloc[train_index], train_Busan_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Busan_2.iloc[train_index], y_train_Busan_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 387,\n",
    "                                  n_estimators = 128, \n",
    "                                  ccp_alpha = 0.028318)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Busan_2 = model.predict(test_Busan_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03194f-c2e1-4b50-8c47-5f8a4d377a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Seoul_1, y_train_Seoul_1):\n",
    "    x_train, x_val = train_Seoul_1.iloc[train_index], train_Seoul_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Seoul_1.iloc[train_index], y_train_Seoul_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 20,\n",
    "                                  max_leaf_nodes = 301,\n",
    "                                  n_estimators = 346, \n",
    "                                  ccp_alpha = 0.060267)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Seoul_1 = model.predict(test_Seoul_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d27ac3-b0df-4bce-8f89-494f1fc86d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Seoul_2, y_train_Seoul_2):\n",
    "    x_train, x_val = train_Seoul_2.iloc[train_index], train_Seoul_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Seoul_2.iloc[train_index], y_train_Seoul_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 613,\n",
    "                                  n_estimators = 149, \n",
    "                                  ccp_alpha = 0.039519)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Seoul_2 = model.predict(test_Seoul_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4059a-133a-4075-a29d-b72be1b069d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Sejong_1, y_train_Sejong_1):\n",
    "    x_train, x_val = train_Sejong_1.iloc[train_index], train_Sejong_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Sejong_1.iloc[train_index], y_train_Sejong_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 6,\n",
    "                                  max_leaf_nodes = 625,\n",
    "                                  n_estimators = 191, \n",
    "                                  ccp_alpha = 0.270342)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Sejong_1 = model.predict(test_Sejong_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffedef-4618-4fc5-96f7-31273549ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Sejong_2, y_train_Sejong_2):\n",
    "    x_train, x_val = train_Sejong_2.iloc[train_index], train_Sejong_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Sejong_2.iloc[train_index], y_train_Sejong_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 17,\n",
    "                                  max_leaf_nodes = 868,\n",
    "                                  n_estimators = 102, \n",
    "                                  ccp_alpha = 0.217719)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Sejong_2 = model.predict(test_Sejong_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d56ec-cd5f-45bd-8c81-b4049b4540a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Incheon_1, y_train_Incheon_1):\n",
    "    x_train, x_val = train_Incheon_1.iloc[train_index], train_Incheon_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Incheon_1.iloc[train_index], y_train_Incheon_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 14,\n",
    "                                  max_leaf_nodes = 3,\n",
    "                                  n_estimators = 460, \n",
    "                                  ccp_alpha = 0.0298)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Incheon_1 = model.predict(test_Incheon_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7972719-aba4-4dea-a50d-35d71b92e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Incheon_2, y_train_Incheon_2):\n",
    "    x_train, x_val = train_Incheon_2.iloc[train_index], train_Incheon_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Incheon_2.iloc[train_index], y_train_Incheon_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 620,\n",
    "                                  n_estimators = 109, \n",
    "                                  ccp_alpha = 0.277405)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Incheon_2 = model.predict(test_Incheon_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be14b4-623c-4267-b213-23bf8b31979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Ulsan_1, y_train_Ulsan_1):\n",
    "    x_train, x_val = train_Ulsan_1.iloc[train_index], train_Ulsan_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Ulsan_1.iloc[train_index], y_train_Ulsan_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 13,\n",
    "                                  max_leaf_nodes = 439,\n",
    "                                  n_estimators = 237, \n",
    "                                  ccp_alpha = 0.010904)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Ulsan_1 = model.predict(test_Ulsan_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8aaf7-49a5-43db-957c-86732a28d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Ulsan_2, y_train_Ulsan_2):\n",
    "    x_train, x_val = train_Ulsan_2.iloc[train_index], train_Ulsan_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Ulsan_2.iloc[train_index], y_train_Ulsan_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 8,\n",
    "                                  max_leaf_nodes = 426,\n",
    "                                  n_estimators = 495, \n",
    "                                  ccp_alpha = 0.362307)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Ulsan_2 = model.predict(test_Ulsan_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c552fb-caf7-49ad-97d6-f0d75bd915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeonnam_1, y_train_Jeonnam_1):\n",
    "    x_train, x_val = train_Jeonnam_1.iloc[train_index], train_Jeonnam_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeonnam_1.iloc[train_index], y_train_Jeonnam_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 5,\n",
    "                                  n_estimators = 327, \n",
    "                                  ccp_alpha =0.032941 )\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeonnam_1 = model.predict(test_Jeonnam_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f94c1-d1f1-4600-bb66-28250bc0a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeonnam_2, y_train_Jeonnam_2):\n",
    "    x_train, x_val = train_Jeonnam_2.iloc[train_index], train_Jeonnam_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeonnam_2.iloc[train_index], y_train_Jeonnam_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 651,\n",
    "                                  n_estimators = 464, \n",
    "                                  ccp_alpha = 0.016249)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeonnam_2 = model.predict(test_Jeonnam_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa7458-93ec-483a-be6d-cc4ee983c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeonbuk_1, y_train_Jeonbuk_1):\n",
    "    x_train, x_val = train_Jeonbuk_1.iloc[train_index], train_Jeonbuk_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeonbuk_1.iloc[train_index], y_train_Jeonbuk_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 802,\n",
    "                                  n_estimators = 284, \n",
    "                                  ccp_alpha = 0.0127)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeonbuk_1 = model.predict(test_Jeonbuk_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424994d-3328-4732-bcaf-5cac99ac8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeonbuk_2, y_train_Jeonbuk_2):\n",
    "    x_train, x_val = train_Jeonbuk_2.iloc[train_index], train_Jeonbuk_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeonbuk_2.iloc[train_index], y_train_Jeonbuk_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 4,\n",
    "                                  max_leaf_nodes = 131,\n",
    "                                  n_estimators = 100, \n",
    "                                  ccp_alpha = 0.0185)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeonbuk_2 = model.predict(test_Jeonbuk_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e93898-28ba-42a6-8883-7ac486d55b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeju_1, y_train_Jeju_1):\n",
    "    x_train, x_val = train_Jeju_1.iloc[train_index], train_Jeju_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeju_1.iloc[train_index], y_train_Jeju_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 20,\n",
    "                                  max_leaf_nodes = 340,\n",
    "                                  n_estimators = 500, \n",
    "                                  ccp_alpha = 0.130184)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeju_1 = model.predict(test_Jeju_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04ab44-f64c-4f77-823b-d264908aaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Jeju_2, y_train_Jeju_2):\n",
    "    x_train, x_val = train_Jeju_2.iloc[train_index], train_Jeju_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Jeju_2.iloc[train_index], y_train_Jeju_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 13,\n",
    "                                  max_leaf_nodes = 624,\n",
    "                                  n_estimators = 375, \n",
    "                                  ccp_alpha = 0.013194)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Jeju_2 = model.predict(test_Jeju_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a664133-01ca-4bdd-a8a9-0337e00b3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Chungnam_1, y_train_Chungnam_1):\n",
    "    x_train, x_val = train_Chungnam_1.iloc[train_index], train_Chungnam_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Chungnam_1.iloc[train_index], y_train_Chungnam_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 15,\n",
    "                                  max_leaf_nodes = 270,\n",
    "                                  n_estimators = 176, \n",
    "                                  ccp_alpha = 0.013357)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Chungnam_1 = model.predict(test_Chungnam_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c58a5-f994-4c03-8bbe-a46479582671",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Chungnam_2, y_train_Chungnam_2):\n",
    "    x_train, x_val = train_Chungnam_2.iloc[train_index], train_Chungnam_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Chungnam_2.iloc[train_index], y_train_Chungnam_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 229,\n",
    "                                  n_estimators = 283, \n",
    "                                  ccp_alpha = 0.982048)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Chungnam_2 = model.predict(test_Chungnam_2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae3eb3-130d-4ec5-83ce-793af4337585",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Chungbuk_1, y_train_Chungbuk_1):\n",
    "    x_train, x_val = train_Chungbuk_1.iloc[train_index], train_Chungbuk_1.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Chungbuk_1.iloc[train_index], y_train_Chungbuk_1.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 3,\n",
    "                                  max_leaf_nodes = 606,\n",
    "                                  n_estimators = 223, \n",
    "                                  ccp_alpha = 0.021476)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Chungbuk_1 = model.predict(test_Chungbuk_1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834128c3-d69c-4e48-8614-4a43497ca7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "rmses=[]\n",
    "for train_index, test_index in str_kf.split(train_Chungbuk_2, y_train_Chungbuk_2):\n",
    "    x_train, x_val = train_Chungbuk_2.iloc[train_index], train_Chungbuk_2.iloc[test_index]\n",
    "    y_trainer, y_val = y_train_Chungbuk_2.iloc[train_index], y_train_Chungbuk_2.iloc[test_index]\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth = 10,\n",
    "                                  max_leaf_nodes = 181,\n",
    "                                  n_estimators = 449, \n",
    "                                  ccp_alpha = 0.016795)\n",
    "    model.fit(x_train,y_trainer)\n",
    "        \n",
    "    y_pred=model.predict(x_val)\n",
    "    rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "    total = np.mean(rmses)\n",
    "        \n",
    "pred_Chungbuk_2 = model.predict(test_Chungbuk_2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8bcca-f607-4c00-9bb2-400c4928fe78",
   "metadata": {},
   "source": [
    "# 2016 예측 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a476dbe-8a71-486b-bbaf-099642d6cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Gangwon_1 = pd.DataFrame({'frequency' : pred_Gangwon_1})\n",
    "pred_Gangwon_2 = pd.DataFrame({'frequency' : pred_Gangwon_2})\n",
    "\n",
    "pred_Gyeonggi_1 = pd.DataFrame({'frequency' : pred_Gyeonggi_1})\n",
    "pred_Gyeonggi_2 = pd.DataFrame({'frequency' : pred_Gyeonggi_2})\n",
    "\n",
    "pred_Gyeongnam_1 = pd.DataFrame({'frequency' : pred_Gyeongnam_1})\n",
    "pred_Gyeongnam_2 = pd.DataFrame({'frequency' : pred_Gyeongnam_2})\n",
    "\n",
    "pred_Gyeongbuk_1 = pd.DataFrame({'frequency' : pred_Gyeongbuk_1})\n",
    "pred_Gyeongbuk_2 = pd.DataFrame({'frequency' : pred_Gyeongbuk_2})\n",
    "\n",
    "pred_Gwangju_1 = pd.DataFrame({'frequency' : pred_Gwangju_1})\n",
    "pred_Gwangju_2 = pd.DataFrame({'frequency' : pred_Gwangju_2})\n",
    "\n",
    "pred_Daegu_1 = pd.DataFrame({'frequency' : pred_Daegu_1})\n",
    "pred_Daegu_2 = pd.DataFrame({'frequency' : pred_Daegu_2})\n",
    "\n",
    "pred_Daejeon_1 = pd.DataFrame({'frequency' : pred_Daejeon_1})\n",
    "pred_Daejeon_2 = pd.DataFrame({'frequency' : pred_Daejeon_2})\n",
    "\n",
    "pred_Busan_1 = pd.DataFrame({'frequency' : pred_Busan_1})\n",
    "pred_Busan_2 = pd.DataFrame({'frequency' : pred_Busan_2})\n",
    "\n",
    "pred_Seoul_1 = pd.DataFrame({'frequency' : pred_Seoul_1})\n",
    "pred_Seoul_2 = pd.DataFrame({'frequency' : pred_Seoul_2})\n",
    "\n",
    "pred_Sejong_1 = pd.DataFrame({'frequency' : pred_Sejong_1})\n",
    "pred_Sejong_2 = pd.DataFrame({'frequency' : pred_Sejong_2})\n",
    "\n",
    "pred_Incheon_1 = pd.DataFrame({'frequency' : pred_Incheon_1})\n",
    "pred_Incheon_2 = pd.DataFrame({'frequency' : pred_Incheon_2})\n",
    "\n",
    "pred_Ulsan_1 = pd.DataFrame({'frequency' : pred_Ulsan_1})\n",
    "pred_Ulsan_2 = pd.DataFrame({'frequency' : pred_Ulsan_2})\n",
    "\n",
    "pred_Jeonnam_1 = pd.DataFrame({'frequency' : pred_Jeonnam_1})\n",
    "pred_Jeonnam_2 = pd.DataFrame({'frequency' : pred_Jeonnam_2})\n",
    "\n",
    "pred_Jeonbuk_1 = pd.DataFrame({'frequency' : pred_Jeonbuk_1})\n",
    "pred_Jeonbuk_2 = pd.DataFrame({'frequency' : pred_Jeonbuk_2})\n",
    "\n",
    "pred_Jeju_1 = pd.DataFrame({'frequency' : pred_Jeju_1})\n",
    "pred_Jeju_2 = pd.DataFrame({'frequency' : pred_Jeju_2})\n",
    "\n",
    "pred_Chungnam_1 = pd.DataFrame({'frequency' : pred_Chungnam_1})\n",
    "pred_Chungnam_2 = pd.DataFrame({'frequency' : pred_Chungnam_2})\n",
    "\n",
    "pred_Chungbuk_1 = pd.DataFrame({'frequency' : pred_Chungbuk_1})\n",
    "pred_Chungbuk_2 = pd.DataFrame({'frequency' : pred_Chungbuk_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fee67-5c8b-4325-8b06-f92c342d4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Gangwon_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gangwon_1['area'] = pd.DataFrame(366*('강원',))\n",
    "pred_Gangwon_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Gangwon_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gangwon_2['area'] = pd.DataFrame(366*('강원',))\n",
    "pred_Gangwon_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Gyeonggi_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeonggi_1['area'] = pd.DataFrame(366*('경기',))\n",
    "pred_Gyeonggi_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Gyeonggi_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeonggi_2['area'] = pd.DataFrame(366*('경기',))\n",
    "pred_Gyeonggi_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Gyeongnam_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeongnam_1['area'] = pd.DataFrame(366*('경남',))\n",
    "pred_Gyeongnam_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Gyeongnam_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeongnam_2['area'] = pd.DataFrame(366*('경남',))\n",
    "pred_Gyeongnam_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Gyeongbuk_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeongbuk_1['area'] = pd.DataFrame(366*('경북',))\n",
    "pred_Gyeongbuk_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Gyeongbuk_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gyeongbuk_2['area'] = pd.DataFrame(366*('경북',))\n",
    "pred_Gyeongbuk_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Gwangju_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gwangju_1['area'] = pd.DataFrame(366*('광주',))\n",
    "pred_Gwangju_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Gwangju_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Gwangju_2['area'] = pd.DataFrame(366*('광주',))\n",
    "pred_Gwangju_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Daegu_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Daegu_1['area'] = pd.DataFrame(366*('대구',))\n",
    "pred_Daegu_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Daegu_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Daegu_2['area'] = pd.DataFrame(366*('대구',))\n",
    "pred_Daegu_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Daejeon_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Daejeon_1['area'] = pd.DataFrame(366*('대전',))\n",
    "pred_Daejeon_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Daejeon_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Daejeon_2['area'] = pd.DataFrame(366*('대전',))\n",
    "pred_Daejeon_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Busan_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Busan_1['area'] = pd.DataFrame(366*('부산',))\n",
    "pred_Busan_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Busan_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Busan_2['area'] = pd.DataFrame(366*('부산',))\n",
    "pred_Busan_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Seoul_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Seoul_1['area'] = pd.DataFrame(366*('서울',))\n",
    "pred_Seoul_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Seoul_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Seoul_2['area'] = pd.DataFrame(366*('서울',))\n",
    "pred_Seoul_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Sejong_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Sejong_1['area'] = pd.DataFrame(366*('세종',))\n",
    "pred_Sejong_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Sejong_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Sejong_2['area'] = pd.DataFrame(366*('세종',))\n",
    "pred_Sejong_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Ulsan_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Ulsan_1['area'] = pd.DataFrame(366*('울산',))\n",
    "pred_Ulsan_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Ulsan_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Ulsan_2['area'] = pd.DataFrame(366*('울산',))\n",
    "pred_Ulsan_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Incheon_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Incheon_1['area'] = pd.DataFrame(366*('인천',))\n",
    "pred_Incheon_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Incheon_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Incheon_2['area'] = pd.DataFrame(366*('인천',))\n",
    "pred_Incheon_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Jeonnam_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeonnam_1['area'] = pd.DataFrame(366*('전남',))\n",
    "pred_Jeonnam_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Jeonnam_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeonnam_2['area'] = pd.DataFrame(366*('전남',))\n",
    "pred_Jeonnam_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Jeonbuk_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeonbuk_1['area'] = pd.DataFrame(366*('전북',))\n",
    "pred_Jeonbuk_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Jeonbuk_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeonbuk_2['area'] = pd.DataFrame(366*('전북',))\n",
    "pred_Jeonbuk_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Jeju_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeju_1['area'] = pd.DataFrame(366*('제주',))\n",
    "pred_Jeju_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Jeju_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Jeju_2['area'] = pd.DataFrame(366*('제주',))\n",
    "pred_Jeju_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Chungnam_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Chungnam_1['area'] = pd.DataFrame(366*('충남',))\n",
    "pred_Chungnam_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Chungnam_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Chungnam_2['area'] = pd.DataFrame(366*('충남',))\n",
    "pred_Chungnam_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n",
    "\n",
    "pred_Chungbuk_1['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Chungbuk_1['area'] = pd.DataFrame(366*('충북',))\n",
    "pred_Chungbuk_1['sex'] = sex = pd.DataFrame(list(366*('1',)))\n",
    "pred_Chungbuk_2['yyyymmdd'] = pd.date_range(start=\"2016-01-01\",end=\"2016-12-31\")\n",
    "pred_Chungbuk_2['area'] = pd.DataFrame(366*('충북',))\n",
    "pred_Chungbuk_2['sex'] = sex = pd.DataFrame(list(366*('2',)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ea93e-b85e-457a-a09e-e31c3f4fbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Gangwon_1['sex'] = pred_Gangwon_1['sex'].astype(int)\n",
    "pred_Gangwon_2['sex'] = pred_Gangwon_2['sex'].astype(int)\n",
    "\n",
    "pred_Gyeonggi_1['sex'] = pred_Gyeonggi_1['sex'].astype(int)\n",
    "pred_Gyeonggi_2['sex'] = pred_Gyeonggi_2['sex'].astype(int)\n",
    "\n",
    "pred_Gyeongnam_1['sex'] = pred_Gyeongnam_1['sex'].astype(int)\n",
    "pred_Gyeongnam_2['sex'] = pred_Gyeongnam_2['sex'].astype(int)\n",
    "\n",
    "pred_Gyeongbuk_1['sex'] = pred_Gyeongbuk_1['sex'].astype(int)\n",
    "pred_Gyeongbuk_2['sex'] = pred_Gyeongbuk_2['sex'].astype(int)\n",
    "\n",
    "pred_Gwangju_1['sex'] = pred_Gwangju_1['sex'].astype(int)\n",
    "pred_Gwangju_2['sex'] = pred_Gwangju_2['sex'].astype(int)\n",
    "\n",
    "pred_Daegu_1['sex'] = pred_Daegu_1['sex'].astype(int)\n",
    "pred_Daegu_2['sex'] = pred_Daegu_2['sex'].astype(int)\n",
    "\n",
    "pred_Daejeon_1['sex'] = pred_Daejeon_1['sex'].astype(int)\n",
    "pred_Daejeon_2['sex'] = pred_Daejeon_2['sex'].astype(int)\n",
    "\n",
    "pred_Busan_1['sex'] = pred_Busan_1['sex'].astype(int)\n",
    "pred_Busan_2['sex'] = pred_Busan_2['sex'].astype(int)\n",
    "\n",
    "pred_Seoul_1['sex'] = pred_Seoul_1['sex'].astype(int)\n",
    "pred_Seoul_2['sex'] = pred_Seoul_2['sex'].astype(int)\n",
    "\n",
    "pred_Sejong_1['sex'] = pred_Sejong_1['sex'].astype(int)\n",
    "pred_Sejong_2['sex'] = pred_Sejong_2['sex'].astype(int)\n",
    "\n",
    "pred_Incheon_1['sex'] = pred_Incheon_1['sex'].astype(int)\n",
    "pred_Incheon_2['sex'] = pred_Incheon_2['sex'].astype(int)\n",
    "\n",
    "pred_Ulsan_1['sex'] = pred_Ulsan_1['sex'].astype(int)\n",
    "pred_Ulsan_2['sex'] = pred_Ulsan_2['sex'].astype(int)\n",
    "\n",
    "pred_Jeonnam_1['sex'] = pred_Jeonnam_1['sex'].astype(int)\n",
    "pred_Jeonnam_2['sex'] = pred_Jeonnam_2['sex'].astype(int)\n",
    "\n",
    "pred_Jeonbuk_1['sex'] = pred_Jeonbuk_1['sex'].astype(int)\n",
    "pred_Jeonbuk_2['sex'] = pred_Jeonbuk_2['sex'].astype(int)\n",
    "\n",
    "pred_Jeju_1['sex'] = pred_Jeju_1['sex'].astype(int)\n",
    "pred_Jeju_2['sex'] = pred_Jeju_2['sex'].astype(int)\n",
    "\n",
    "pred_Chungnam_1['sex'] = pred_Chungnam_1['sex'].astype(int)\n",
    "pred_Chungnam_2['sex'] = pred_Chungnam_2['sex'].astype(int)\n",
    "\n",
    "pred_Chungbuk_1['sex'] = pred_Chungbuk_1['sex'].astype(int)\n",
    "pred_Chungbuk_2['sex'] = pred_Chungbuk_2['sex'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2b2ff-894d-4a6b-9f10-5469d4b75162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Gangwon_1['yyyymmdd'] = pred_Gangwon_1['yyyymmdd'].astype(str)\n",
    "pred_Gangwon_2['yyyymmdd'] = pred_Gangwon_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Gyeonggi_1['yyyymmdd'] = pred_Gyeonggi_1['yyyymmdd'].astype(str)\n",
    "pred_Gyeonggi_2['yyyymmdd'] = pred_Gyeonggi_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Gyeongnam_1['yyyymmdd'] = pred_Gyeongnam_1['yyyymmdd'].astype(str)\n",
    "pred_Gyeongnam_2['yyyymmdd'] = pred_Gyeongnam_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Gyeongbuk_1['yyyymmdd'] = pred_Gyeongbuk_1['yyyymmdd'].astype(str)\n",
    "pred_Gyeongbuk_2['yyyymmdd'] = pred_Gyeongbuk_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Gwangju_1['yyyymmdd'] = pred_Gwangju_1['yyyymmdd'].astype(str)\n",
    "pred_Gwangju_2['yyyymmdd'] = pred_Gwangju_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Daegu_1['yyyymmdd'] = pred_Daegu_1['yyyymmdd'].astype(str)\n",
    "pred_Daegu_2['yyyymmdd'] = pred_Daegu_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Daejeon_1['yyyymmdd'] = pred_Daejeon_1['yyyymmdd'].astype(str)\n",
    "pred_Daejeon_2['yyyymmdd'] = pred_Daejeon_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Busan_1['yyyymmdd'] = pred_Busan_1['yyyymmdd'].astype(str)\n",
    "pred_Busan_2['yyyymmdd'] = pred_Busan_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Seoul_1['yyyymmdd'] = pred_Seoul_1['yyyymmdd'].astype(str)\n",
    "pred_Seoul_2['yyyymmdd'] = pred_Seoul_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Sejong_1['yyyymmdd'] = pred_Sejong_1['yyyymmdd'].astype(str)\n",
    "pred_Sejong_2['yyyymmdd'] = pred_Sejong_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Incheon_1['yyyymmdd'] = pred_Incheon_1['yyyymmdd'].astype(str)\n",
    "pred_Incheon_2['yyyymmdd'] = pred_Incheon_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Ulsan_1['yyyymmdd'] = pred_Ulsan_1['yyyymmdd'].astype(str)\n",
    "pred_Ulsan_2['yyyymmdd'] = pred_Ulsan_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Jeonnam_1['yyyymmdd'] = pred_Jeonnam_1['yyyymmdd'].astype(str)\n",
    "pred_Jeonnam_2['yyyymmdd'] = pred_Jeonnam_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Jeonbuk_1['yyyymmdd'] = pred_Jeonbuk_1['yyyymmdd'].astype(str)\n",
    "pred_Jeonbuk_2['yyyymmdd'] = pred_Jeonbuk_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Jeju_1['yyyymmdd'] = pred_Jeju_1['yyyymmdd'].astype(str)\n",
    "pred_Jeju_2['yyyymmdd'] = pred_Jeju_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Chungnam_1['yyyymmdd'] = pred_Chungnam_1['yyyymmdd'].astype(str)\n",
    "pred_Chungnam_2['yyyymmdd'] = pred_Chungnam_2['yyyymmdd'].astype(str)\n",
    "\n",
    "pred_Chungbuk_1['yyyymmdd'] = pred_Chungbuk_1['yyyymmdd'].astype(str)\n",
    "pred_Chungbuk_2['yyyymmdd'] = pred_Chungbuk_2['yyyymmdd'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414097f4-824d-434a-8418-32000492809d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv('/home/jupyter/climate/data/back_testset.csv')\n",
    "# valid.drop(['frequency'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b600e24-79e2-4f78-9b04-830eeb912cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_Gangwon_1 = pd.merge(valid, pred_Gangwon_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Gangwon_2 = pd.merge(valid, pred_Gangwon_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Gyeonggi_1 = pd.merge(valid, pred_Gyeonggi_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Gyeonggi_2 = pd.merge(valid, pred_Gyeonggi_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Gyeongnam_1 = pd.merge(valid, pred_Gyeongnam_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Gyeongnam_2 = pd.merge(valid, pred_Gyeongnam_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Gyeongbuk_1 = pd.merge(valid, pred_Gyeongbuk_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Gyeongbuk_2 = pd.merge(valid, pred_Gyeongbuk_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Gwangju_1 = pd.merge(valid, pred_Gwangju_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Gwangju_2 = pd.merge(valid, pred_Gwangju_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Daegu_1 = pd.merge(valid, pred_Daegu_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Daegu_2 = pd.merge(valid, pred_Daegu_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Daejeon_1 = pd.merge(valid, pred_Daejeon_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Daejeon_2 = pd.merge(valid, pred_Daejeon_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Busan_1 = pd.merge(valid, pred_Busan_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Busan_2 = pd.merge(valid, pred_Busan_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Seoul_1 = pd.merge(valid, pred_Seoul_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Seoul_2 = pd.merge(valid, pred_Seoul_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Sejong_1 = pd.merge(valid, pred_Sejong_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Sejong_2 = pd.merge(valid, pred_Sejong_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Incheon_1 = pd.merge(valid, pred_Incheon_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Incheon_2 = pd.merge(valid, pred_Incheon_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Ulsan_1 = pd.merge(valid, pred_Ulsan_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Ulsan_2 = pd.merge(valid, pred_Ulsan_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Jeonnam_1 = pd.merge(valid, pred_Jeonnam_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Jeonnam_2 = pd.merge(valid, pred_Jeonnam_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Jeonbuk_1 = pd.merge(valid, pred_Jeonbuk_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Jeonbuk_2 = pd.merge(valid, pred_Jeonbuk_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Jeju_1 = pd.merge(valid, pred_Jeju_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Jeju_2 = pd.merge(valid, pred_Jeju_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Chungnam_1 = pd.merge(valid, pred_Chungnam_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Chungnam_2 = pd.merge(valid, pred_Chungnam_2, on = ['area','sex','yyyymmdd'])\n",
    "\n",
    "merged_Chungbuk_1 = pd.merge(valid, pred_Chungbuk_1, on = ['area','sex','yyyymmdd'])\n",
    "merged_Chungbuk_2 = pd.merge(valid, pred_Chungbuk_2, on = ['area','sex','yyyymmdd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb440d-273d-4544-ba6d-aabd94bca59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gangwon = merged_Gangwon_1.append(merged_Gangwon_2)\n",
    "Gyeonggi = merged_Gyeonggi_1.append(merged_Gyeonggi_2)\n",
    "Gyeongnam = merged_Gyeongnam_1.append(merged_Gyeongnam_2)\n",
    "Gyeongbuk = merged_Gyeongbuk_1.append(merged_Gyeongbuk_2)\n",
    "Gwangju = merged_Gwangju_1.append(merged_Gwangju_2)\n",
    "Daegu = merged_Daegu_1.append(merged_Daegu_2)\n",
    "Daejeon = merged_Daejeon_1.append(merged_Daejeon_2)\n",
    "Busan = merged_Busan_1.append(merged_Busan_2)\n",
    "Seoul = merged_Seoul_1.append(merged_Seoul_2)\n",
    "Sejong = merged_Sejong_1.append(merged_Sejong_2)\n",
    "Incheon = merged_Incheon_1.append(merged_Incheon_2)\n",
    "Ulsan = merged_Ulsan_1.append(merged_Ulsan_2)\n",
    "Jeonnam = merged_Jeonnam_1.append(merged_Jeonnam_2)\n",
    "Jeonbuk = merged_Jeonbuk_1.append(merged_Jeonbuk_2)\n",
    "Jeju = merged_Jeju_1.append(merged_Jeju_2)\n",
    "Chungnam = merged_Chungnam_1.append(merged_Chungnam_2)\n",
    "Chungbuk = merged_Chungbuk_1.append(merged_Chungbuk_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c9a47-26a2-438f-83f6-f488b9a8557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full = Gangwon.append([Gyeonggi, Gyeongnam, Gyeongbuk, Gwangju, Daegu, Daejeon, Busan, Seoul, Sejong, Incheon, Ulsan, Jeonnam, Jeonbuk, Jeju, Chungnam, Chungbuk])\n",
    "full['yyyymmdd'] = pd.to_datetime(full['yyyymmdd'], format='%Y-%m-%d')\n",
    "full_1 = full.sort_values(['yyyymmdd', 'sex', 'area'], ascending=[True, True, True])\n",
    "valid['frequency'] = pd.DataFrame(list(full_1['frequency_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f7c3b-178d-41f9-a8c8-e69c0f892a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847588a-dec6-4fbb-b126-296e257df466",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv('/home/jupyter/climate/data/220194.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9be3b6-5556-426f-994f-43a12cddd680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38433b-7c93-41ff-8a1a-24bca49d65e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
