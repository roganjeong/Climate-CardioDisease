{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import inspect\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_raw_df = pd.read_csv('e:/kma/data/TRAIN_tree_with_파생변수_euc-kr0804 (1).csv', encoding='cp949')\n",
    "train_raw_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "col_list = train_raw_df.columns\n",
    "\n",
    "full_raw_df = train_raw_df\n",
    "\n",
    "full_raw_df = full_raw_df.astype({'yyyymmdd':'str'})\n",
    "full_raw_df['yyyymmdd'] = pd.to_datetime(full_raw_df['yyyymmdd'])\n",
    "full_raw_df\n",
    "\n",
    "\n",
    "add_list = set(full_raw_df['add'])\n",
    "indep_cols = full_raw_df.columns.difference(['yyyymmdd', 'add', 'sex', 'frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(full_data):\n",
    "    \n",
    "    # scaling\n",
    "    scaler_x = StandardScaler()\n",
    "    scaled_df = scaler_x.fit_transform(full_data[indep_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=indep_cols)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    scaled_df['frequency'] = scaler_y.fit_transform(full_data['frequency'].values.reshape(-1,1))\n",
    "\n",
    "    dump(scaler_x, open('e:/kma/scaler/scaler_x_{0}_{1}_{2}_{3}.pkl'.format(model_nm, sido, sex, nowDatetime), 'wb'))\n",
    "    dump(scaler_y, open('e:/kma/scaler/scaler_y_{0}_{1}_{2}_{3}.pkl'.format(model_nm, sido, sex, nowDatetime), 'wb'))\n",
    "    \n",
    "    return scaler_x, scaler_y, scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lstm에 맞게 데이터 구조 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 파라미터 feature, label => numpy type\n",
    "# 아래 pre_processing 함수에서 쓰임\n",
    "def make_sequene_dataset(feature, label, window_size):\n",
    "\n",
    "    feature_list = []      # 생성될 feature list\n",
    "    label_list = []        # 생성될 label list\n",
    "\n",
    "    for i in range(len(feature)-window_size):\n",
    "\n",
    "        feature_list.append(feature[i:i+window_size])\n",
    "        label_list.append(label[i+window_size])\n",
    "\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(scaled_df, window_size):\n",
    "    \n",
    "    # feature_df, label_df 생성\n",
    "    feature_df = pd.DataFrame(scaled_df, columns=indep_cols)\n",
    "    label_df = pd.DataFrame(scaled_df['frequency'])\n",
    "\n",
    "    # DataFrame => Numpy 변환\n",
    "    feature_np = feature_df.to_numpy()\n",
    "    label_np = label_df.to_numpy()\n",
    "    print(feature_np.shape, label_np.shape)\n",
    "    # print(\"__________________________________\")\n",
    "\n",
    "    # 시계열 데이터 생성 (make_sequence_dataset)\n",
    "    X, Y = make_sequene_dataset(feature_np, label_np, window_size)\n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lstm 모델 생성 및 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "\n",
    "def make_model(train_x_data):\n",
    "        input_dim = train_x_data[0].shape\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(256, activation='relu', input_shape=input_dim))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        \n",
    "        # model.compile(loss='mse', optimizer='rmsprop', metrics=['mse'])\n",
    "        model.compile(loss=root_mean_squared_error, optimizer='rmsprop', metrics=['mse'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시도별 성별 lstm 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "nowDatetime = now.strftime('%m%d_%H%M')\n",
    "\n",
    "result = pd.DataFrame(columns=['sido', 'sex', 'rmse'])\n",
    "LB_result = pd.DataFrame(columns=['yyyymmdd', 'sido', 'sex', 'frequency'])\n",
    "\n",
    "model_nm = \"lstm\"\n",
    "\n",
    "# sido = '서울'\n",
    "# sex = 1\n",
    "for sido in add_list:#('광주','서울'):\n",
    "    for sex in (1,2):\n",
    "        # #-------------------------------------------------------------------------------------------#\n",
    "        print(\"============================\", sido, sex, \"============================\")\n",
    "\n",
    "        condition = (full_raw_df['add']==sido) & (full_raw_df['sex']==sex)        \n",
    "        tmp = full_raw_df.copy()[condition]\n",
    "        tmp.reset_index(level=0, inplace=True, drop=True)\n",
    "\n",
    "\n",
    "        # lstm에 넣을 수 있도록 데이터 형태 변환\n",
    "        scaler_x, scaler_y, scaled_df = scaling(tmp)\n",
    "        X, Y = pre_processing(scaled_df, 7)\n",
    "\n",
    "\n",
    "        # 12~14 train, 15 valid 분리\n",
    "        x_train = X[0:-365]\n",
    "        y_train = Y[0:-365]\n",
    "\n",
    "        x_valid = X[-365:]\n",
    "        y_valid = Y[-365:]\n",
    "\n",
    "\n",
    "        # model 생성 및 compile\n",
    "        model = make_model(x_train)\n",
    "\n",
    "        # model fitting\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "        history = model.fit(x_train, y_train, \n",
    "                            validation_data=(x_valid, y_valid),\n",
    "                            epochs=500, batch_size=512,\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stop])\n",
    "        # model.save('e:/kma/model/{0}_{1}_{2}_{3}.h5'.format(model_nm, sido, sex, nowDatetime))\n",
    "\n",
    "\n",
    "        # 2015 valid 셋으로 rmse 확인--------------------------\n",
    "        # 그래프 확인\n",
    "        pred_valid = model.predict(x_valid)\n",
    "        rescaled_y_valid = scaler_y.inverse_transform(np.array(y_valid).reshape(-1,1))\n",
    "        rescaled_pred_valid= scaler_y.inverse_transform(np.array(pred_valid).reshape(-1,1))\n",
    "\n",
    "        # rmse\n",
    "        rmse = mean_squared_error(rescaled_y_valid, rescaled_pred_valid, squared=False)\n",
    "        print(rmse)\n",
    "        result_tmp = pd.DataFrame([[sido, sex, rmse]], columns=['sido', 'sex', 'rmse'])\n",
    "        result = pd.concat([result, result_tmp])\n",
    "        #-------------------------------------------------------\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# 2015 valid셋 rmse 결과 저장\n",
    "result.to_csv('e:/kma/rmse/{0}_{1}.csv'.format(model_nm, nowDatetime), encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, custom_loss, x_concat_data, y_concat_data, epoch=200, batch_size=24, n_splits=5, kf_shuffle=True):\n",
    "        from sklearn.model_selection import KFold\n",
    "        skf = KFold(n_splits=n_splits, shuffle=kf_shuffle)\n",
    "                    \n",
    "        # 계산과 수행\n",
    "        with tf.device('/gpu:0'):\n",
    "            accuracy = []\n",
    "            model.compile(loss='mean_absolute_percentage_error', optimizer=Adam(lr=0.001))\n",
    "            for train, validation in skf.split(x_concat_data, y_concat_data):\n",
    "                print('train valid rate :', len(train),len(validation))\n",
    "                model.fit(x_concat_data[train], y_concat_data[train], batch_size=batch_size, epochs=epoch, verbose=2, shuffle=True)\n",
    "\n",
    "                score = model.evaluate(x_concat_data[validation], y_concat_data[validation], batch_size=batch_size)\n",
    "                accuracy.append(score)\n",
    "\n",
    "\n",
    "            print('\\nK-fold cross validation score: {}'.format(accuracy))\n",
    "\n",
    "        return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "\n",
    "    rmses=[]\n",
    "\n",
    "    for train_index, test_index in str_kf.split(x_full_Gangwon_1, y_full_Gangwon_1):\n",
    "        x_train, x_val = x_full_Gangwon_1.iloc[train_index], x_full_Gangwon_1.iloc[test_index]\n",
    "        y_train, y_val = y_full_Gangwon_1.iloc[train_index], y_full_Gangwon_1.iloc[test_index]\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params, random_state = 6, use_label_encoder = False)\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred=model.predict(x_val)\n",
    "        rmses.append(round(sqrt(mean_squared_error(y_val, y_pred)),6))\n",
    "        total=np.mean(rmses)\n",
    "        \n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('optuna_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c1974f32d22b09ead4d1878234632a8c7e025eaf154a2ba0a2db4a390bb37ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
